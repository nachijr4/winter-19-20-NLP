{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading all english stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lancaster = LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to get all the files in the directory and make a lixst of all the text\n",
    "current_directory = os.getcwd()\n",
    "file_directory = os.listdir(current_directory)\n",
    "document_list = {}\n",
    "for doc in file_directory:\n",
    "        if \".txt\" in doc:\n",
    "                document_list[doc]= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary with the document name as the key and all the word with the stopwords removed as the value and parallely making the same for stemmed words also \n",
    "stemmed_doc_list = {}\n",
    "make_dataframe = {}\n",
    "make_dataframe['document'] = list(document_list.keys())\n",
    "all_words = list()\n",
    "stemmed_words = list()\n",
    "for document in make_dataframe['document']:\n",
    "        document_path = os.getcwd()+\"\\\\\"+document\n",
    "        opened_file = open(document_path,'r').read()\n",
    "        document_list[document] = [word for word in word_tokenize(opened_file.lower()) if word not in stop_words]\n",
    "        stemmed_doc_list[document] = [lancaster.stem(word) for word in document_list[document]]\n",
    "        stemmed_words = stemmed_words + stemmed_doc_list[document]\n",
    "        all_words = all_words + document_list[document]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the list of all the words unique\n",
    "all_words = set(all_words)\n",
    "stemmed_words = set(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary with word count in each document to make a dataframe\n",
    "for word in all_words:\n",
    "        make_dataframe[word] = []\n",
    "        for document in make_dataframe['document']:\n",
    "            make_dataframe[word].append(document_list[document].count(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_dataframe = {}\n",
    "stemmed_dataframe['document'] = list(document_list.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary with word count in each document for all the stemmed words\n",
    "for document in stemmed_dataframe['document']:\n",
    "        stemmed_dataframe[document] = []\n",
    "        for word in stemmed_words:\n",
    "            stemmed_dataframe[document].append(stemmed_doc_list[document].count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the frequency values for all the words present in all the documents\n",
    "dataframe = pd.DataFrame(make_dataframe)\n",
    "var = dataframe.values\n",
    "document_dictionary = dict()\n",
    "for row in var:\n",
    "    row = list(row)\n",
    "    document_dictionary[row[0]] = row[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the cosine similarity \n",
    "def cosine_similarity(doc1, doc2):\n",
    "    return 1 - spatial.distance.cosine(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in var:\n",
    "    row = list(row)\n",
    "    document_dictionary[row[0]] = row[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_cosine_similarities = dict()\n",
    "doc_cosine_stemmed_similarities = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making dictionaries for two dataframes, one for holding all the cosine similarities of non stemmed documents\n",
    "# and another for all the stemmed documents\n",
    "doc_cosine_similarities['Name'] = make_dataframe['document']\n",
    "doc_cosine_stemmed_similarities['Name'] = make_dataframe['document']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the cosine similarity between all the documents. All combinations of documents are considered and cosine similarity is performed\n",
    "for doc1 in make_dataframe['document']:\n",
    "    doc_cosine_similarities[doc1] = []\n",
    "    doc_cosine_stemmed_similarities[doc1] = []\n",
    "    for doc2 in make_dataframe['document']:\n",
    "        doc_cosine_similarities[doc1].append(cosine_similarity(document_dictionary[doc1], document_dictionary[doc2]))\n",
    "        doc_cosine_stemmed_similarities[doc1].append(cosine_similarity(stemmed_dataframe[doc1], stemmed_dataframe[doc2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Name  after life.txt  after life2.txt  atwood.txt  \\\n0                after life.txt        1.000000         0.512197    0.526721   \n1               after life2.txt        0.512197         1.000000    0.744264   \n2                    atwood.txt        0.526721         0.744264    1.000000   \n3                      book.txt        0.546169         0.678727    0.653215   \n4              commencement.txt        0.516671         0.685781    0.676839   \n5                  humanity.txt        0.544146         0.597337    0.655799   \n6   margaret toronto speech.txt        0.515898         0.745832    0.747502   \n7  margaret toronto speech2.txt        0.472313         0.708776    0.921949   \n8                right side.txt        0.469076         0.580946    0.618152   \n9                why go out.txt        0.557332         0.461117    0.578739   \n\n   book.txt  commencement.txt  humanity.txt  margaret toronto speech.txt  \\\n0  0.546169          0.516671      0.544146                     0.515898   \n1  0.678727          0.685781      0.597337                     0.745832   \n2  0.653215          0.676839      0.655799                     0.747502   \n3  1.000000          0.629104      0.600380                     0.672754   \n4  0.629104          1.000000      0.623258                     0.666776   \n5  0.600380          0.623258      1.000000                     0.653481   \n6  0.672754          0.666776      0.653481                     1.000000   \n7  0.613433          0.631106      0.608773                     0.702433   \n8  0.566986          0.573092      0.666405                     0.615455   \n9  0.521430          0.551886      0.667754                     0.564096   \n\n   margaret toronto speech2.txt  right side.txt  why go out.txt  \n0                      0.472313        0.469076        0.557332  \n1                      0.708776        0.580946        0.461117  \n2                      0.921949        0.618152        0.578739  \n3                      0.613433        0.566986        0.521430  \n4                      0.631106        0.573092        0.551886  \n5                      0.608773        0.666405        0.667754  \n6                      0.702433        0.615455        0.564096  \n7                      1.000000        0.578911        0.536481  \n8                      0.578911        1.000000        0.576087  \n9                      0.536481        0.576087        1.000000  \n                           Name  after life.txt  after life2.txt  atwood.txt  \\\n0                after life.txt        1.000000         0.516618    0.523085   \n1               after life2.txt        0.516618         1.000000    0.736417   \n2                    atwood.txt        0.523085         0.736417    1.000000   \n3                      book.txt        0.542139         0.679271    0.640195   \n4              commencement.txt        0.540762         0.672481    0.665465   \n5                  humanity.txt        0.531144         0.578870    0.630820   \n6   margaret toronto speech.txt        0.520257         0.742882    0.746115   \n7  margaret toronto speech2.txt        0.474466         0.711197    0.924837   \n8                right side.txt        0.466329         0.580105    0.610087   \n9                why go out.txt        0.558788         0.463812    0.560385   \n\n   book.txt  commencement.txt  humanity.txt  margaret toronto speech.txt  \\\n0  0.542139          0.540762      0.531144                     0.520257   \n1  0.679271          0.672481      0.578870                     0.742882   \n2  0.640195          0.665465      0.630820                     0.746115   \n3  1.000000          0.621851      0.593309                     0.667673   \n4  0.621851          1.000000      0.596423                     0.654067   \n5  0.593309          0.596423      1.000000                     0.640945   \n6  0.667673          0.654067      0.640945                     1.000000   \n7  0.609705          0.621131      0.591500                     0.704894   \n8  0.573835          0.556824      0.648328                     0.611880   \n9  0.503903          0.529292      0.629388                     0.553004   \n\n   margaret toronto speech2.txt  right side.txt  why go out.txt  \n0                      0.474466        0.466329        0.558788  \n1                      0.711197        0.580105        0.463812  \n2                      0.924837        0.610087        0.560385  \n3                      0.609705        0.573835        0.503903  \n4                      0.621131        0.556824        0.529292  \n5                      0.591500        0.648328        0.629388  \n6                      0.704894        0.611880        0.553004  \n7                      1.000000        0.575772        0.528202  \n8                      0.575772        1.000000        0.562794  \n9                      0.528202        0.562794        1.000000  \n"
    }
   ],
   "source": [
    "# printing the dataframe which displays the similarity of a particular document with all the other documents. \n",
    "doc_cosine_similarities = pd.DataFrame(doc_cosine_similarities)\n",
    "doc_cosine_stemmed_similarities = pd.DataFrame(doc_cosine_stemmed_similarities)\n",
    "print(doc_cosine_similarities)\n",
    "print(doc_cosine_stemmed_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting input as two document names\n",
    "doc1 = input(\"Enter document 1 name:\")\n",
    "doc2 = input(\"Enter document 2 name:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Cosine Similarity of non stemmed documents:  0.5441460820207317\nCosine Similarity of stemmed documents:  0.5311441818330586\n"
    }
   ],
   "source": [
    "# printing the cosine similarity of those two particular documents\n",
    "print(\"Cosine Similarity of non stemmed documents: \",cosine_similarity(document_dictionary[doc1], document_dictionary[doc2]))\n",
    "print(\"Cosine Similarity of stemmed documents: \",cosine_similarity(stemmed_dataframe[doc1], stemmed_dataframe[doc2]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}