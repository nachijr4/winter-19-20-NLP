{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['here',\n 'there',\n 'when',\n 'where',\n 'why',\n 'how',\n 'all',\n 'any',\n 'both',\n 'each',\n 'few',\n 'more',\n 'most',\n 'other',\n 'some',\n 'such',\n 'no',\n 'nor',\n 'not',\n 'only']"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Viewing few stopwords in english\n",
    "stopwords.words('english')[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['tuya',\n 'tuyos',\n 'tuyas',\n 'suyo',\n 'suya',\n 'suyos',\n 'suyas',\n 'nuestro',\n 'nuestra',\n 'nuestros',\n 'nuestras',\n 'vuestro',\n 'vuestra',\n 'vuestros',\n 'vuestras',\n 'esos',\n 'esas',\n 'estoy',\n 'estás',\n 'está']"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Viewing few stopwords in spanish\n",
    "stopwords.words('spanish')[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['hatten',\n 'hier',\n 'hin',\n 'hinter',\n 'ich',\n 'mich',\n 'mir',\n 'ihr',\n 'ihre',\n 'ihrem',\n 'ihren',\n 'ihrer',\n 'ihres',\n 'euch',\n 'im',\n 'in',\n 'indem',\n 'ins',\n 'ist',\n 'jede']"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Viewing few stopwords in spanish\n",
    "stopwords.words('german')[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMU words\n",
    "from nltk.corpus import cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "133737\n[('a', ['AH0']), ('a.', ['EY1']), ('a', ['EY1']), ...]\n"
    }
   ],
   "source": [
    "entries = cmudict.entries()\n",
    "print(len(entries))\n",
    "print(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('bellinghausen', ['B', 'EH1', 'L', 'IH0', 'NG', 'HH', 'AW2', 'Z', 'AH0', 'N'])\n('bellini', ['B', 'EH0', 'L', 'IY1', 'N', 'IY0'])\n(\"bellini's\", ['B', 'EH0', 'L', 'IY1', 'N', 'IY0', 'Z'])\n('bellino', ['B', 'EH0', 'L', 'IY1', 'N', 'OW0'])\n('bellis', ['B', 'EH1', 'L', 'IH0', 'S'])\n('bellissimo', ['B', 'EH0', 'L', 'IY0', 'S', 'IY1', 'M', 'OW0'])\n('belliveau', ['B', 'EH1', 'L', 'IH0', 'V', 'OW2'])\n('bellizzi', ['B', 'EH0', 'L', 'IY1', 'T', 'S', 'IY0'])\n('bellm', ['B', 'EH1', 'L', 'M'])\n('bellman', ['B', 'EH1', 'L', 'M', 'AH0', 'N'])\n"
    }
   ],
   "source": [
    "# printing entries from 10100 to 10110\n",
    "for entry in entries[10100:10110]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[Synset('run.v.01'),\n Synset('scat.v.01'),\n Synset('run.v.03'),\n Synset('operate.v.01'),\n Synset('run.v.05'),\n Synset('run.v.06'),\n Synset('function.v.01'),\n Synset('range.v.01'),\n Synset('campaign.v.01'),\n Synset('play.v.18'),\n Synset('run.v.11'),\n Synset('tend.v.01'),\n Synset('run.v.13'),\n Synset('run.v.14'),\n Synset('run.v.15'),\n Synset('run.v.16'),\n Synset('prevail.v.03'),\n Synset('run.v.18'),\n Synset('run.v.19'),\n Synset('carry.v.15'),\n Synset('run.v.21'),\n Synset('guide.v.05'),\n Synset('run.v.23'),\n Synset('run.v.24'),\n Synset('run.v.25'),\n Synset('run.v.26'),\n Synset('run.v.27'),\n Synset('run.v.28'),\n Synset('run.v.29'),\n Synset('run.v.30'),\n Synset('run.v.31'),\n Synset('run.v.32'),\n Synset('run.v.33'),\n Synset('run.v.34'),\n Synset('ply.v.03'),\n Synset('hunt.v.01'),\n Synset('race.v.02'),\n Synset('move.v.13'),\n Synset('melt.v.01'),\n Synset('ladder.v.01'),\n Synset('run.v.41')]"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# working with wordnet corpus\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('ran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['operate', 'run']"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "wn.synset('operate.v.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['race', 'run']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "wn.synset('race.v.02').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK pipeline. Getting the input data ready\n",
    "import nltk\n",
    "paragraphs = ['''Downey was born April 4, 1965 in Manhattan, New York, the son of writer, director and filmographer \n",
    "Robert Downey Sr. and actress Elsie Downey (née Elsie Ann Ford). Robert's father is of half Lithuanian Jewish, \n",
    "one quarter Hungarian Jewish, and one quarter Irish, descent, while Robert's mother was of English, Scottish,\n",
    "German, and Swiss-German ancestry. Robert and his sister, Allyson Downey, were immersed in film and the \n",
    "performing arts from a very young age, leading Downey Jr. to study at the Stagedoor Manor Performing Arts \n",
    "Training Center in upstate New York, before moving to California with his father following his parents' 1978 divorce. \n",
    "In 1982, he dropped out of Santa Monica High School to pursue acting full time. Downey Sr., himself a drug addict, \n",
    "exposed his son to drugs at a very early age, and Downey Jr. would go on to struggle with abuse for decades.''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Downey', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('April', 'NNP'), ('4', 'CD'), (',', ','), ('1965', 'CD'), ('in', 'IN'), ('Manhattan', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('the', 'DT'), ('son', 'NN'), ('of', 'IN'), ('writer', 'NN'), (',', ','), ('director', 'NN'), ('and', 'CC'), ('filmographer', 'NN'), ('Robert', 'NNP'), ('Downey', 'NNP'), ('Sr.', 'NNP'), ('and', 'CC'), ('actress', 'JJ'), ('Elsie', 'NNP'), ('Downey', 'NNP'), ('(', '('), ('née', 'JJ'), ('Elsie', 'NNP'), ('Ann', 'NNP'), ('Ford', 'NNP'), (')', ')'), ('.', '.')]\n[('Robert', 'NNP'), (\"'s\", 'POS'), ('father', 'NN'), ('is', 'VBZ'), ('of', 'IN'), ('half', 'NN'), ('Lithuanian', 'JJ'), ('Jewish', 'NNP'), (',', ','), ('one', 'CD'), ('quarter', 'NN'), ('Hungarian', 'JJ'), ('Jewish', 'NNP'), (',', ','), ('and', 'CC'), ('one', 'CD'), ('quarter', 'NN'), ('Irish', 'NNP'), (',', ','), ('descent', 'NN'), (',', ','), ('while', 'IN'), ('Robert', 'NNP'), (\"'s\", 'POS'), ('mother', 'NN'), ('was', 'VBD'), ('of', 'IN'), ('English', 'NNP'), (',', ','), ('Scottish', 'NNP'), (',', ','), ('German', 'NNP'), (',', ','), ('and', 'CC'), ('Swiss-German', 'NNP'), ('ancestry', 'NN'), ('.', '.')]\n[('Robert', 'NNP'), ('and', 'CC'), ('his', 'PRP$'), ('sister', 'NN'), (',', ','), ('Allyson', 'NNP'), ('Downey', 'NNP'), (',', ','), ('were', 'VBD'), ('immersed', 'VBN'), ('in', 'IN'), ('film', 'NN'), ('and', 'CC'), ('the', 'DT'), ('performing', 'NN'), ('arts', 'NNS'), ('from', 'IN'), ('a', 'DT'), ('very', 'RB'), ('young', 'JJ'), ('age', 'NN'), (',', ','), ('leading', 'VBG'), ('Downey', 'NNP'), ('Jr.', 'NNP'), ('to', 'TO'), ('study', 'VB'), ('at', 'IN'), ('the', 'DT'), ('Stagedoor', 'NNP'), ('Manor', 'NNP'), ('Performing', 'NNP'), ('Arts', 'NNP'), ('Training', 'NNP'), ('Center', 'NNP'), ('in', 'IN'), ('upstate', 'JJ'), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('before', 'IN'), ('moving', 'VBG'), ('to', 'TO'), ('California', 'NNP'), ('with', 'IN'), ('his', 'PRP$'), ('father', 'NN'), ('following', 'VBG'), ('his', 'PRP$'), ('parents', 'NNS'), (\"'\", 'POS'), ('1978', 'CD'), ('divorce', 'NN'), ('.', '.')]\n[('In', 'IN'), ('1982', 'CD'), (',', ','), ('he', 'PRP'), ('dropped', 'VBD'), ('out', 'IN'), ('of', 'IN'), ('Santa', 'NNP'), ('Monica', 'NNP'), ('High', 'NNP'), ('School', 'NNP'), ('to', 'TO'), ('pursue', 'VB'), ('acting', 'VBG'), ('full', 'JJ'), ('time', 'NN'), ('.', '.')]\n[('Downey', 'NNP'), ('Sr.', 'NNP'), (',', ','), ('himself', 'PRP'), ('a', 'DT'), ('drug', 'NN'), ('addict', 'NN'), (',', ','), ('exposed', 'VBD'), ('his', 'PRP$'), ('son', 'NN'), ('to', 'TO'), ('drugs', 'NNS'), ('at', 'IN'), ('a', 'DT'), ('very', 'RB'), ('early', 'JJ'), ('age', 'NN'), (',', ','), ('and', 'CC'), ('Downey', 'NNP'), ('Jr.', 'NNP'), ('would', 'MD'), ('go', 'VB'), ('on', 'IN'), ('to', 'TO'), ('struggle', 'VB'), ('with', 'IN'), ('abuse', 'NN'), ('for', 'IN'), ('decades', 'NNS'), ('.', '.')]\n"
    }
   ],
   "source": [
    "# tokenizing and pos tagging all the words\n",
    "for para in paragraphs:\n",
    "    sentences = nltk.sent_tokenize(para)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Downey', 'NNP'), ('was', 'VBD'), ('born', 'VBN'), ('April', 'NNP'), ('4', 'CD'), (',', ','), ('1965', 'CD'), ('in', 'IN'), ('Manhattan', 'NNP'), (',', ','), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('the', 'DT'), ('son', 'NN'), ('of', 'IN'), ('writer', 'NN'), (',', ','), ('director', 'NN'), ('and', 'CC'), ('filmographer', 'NN'), ('Robert', 'NNP'), ('Downey', 'NNP'), ('Sr.', 'NNP'), ('and', 'CC'), ('actress', 'JJ'), ('Elsie', 'NNP'), ('Downey', 'NNP'), ('(', '('), ('née', 'JJ'), ('Elsie', 'NNP'), ('Ann', 'NNP'), ('Ford', 'NNP'), (')', ')'), ('.', '.'), ('Robert', 'NNP'), (\"'s\", 'POS'), ('father', 'NN'), ('is', 'VBZ'), ('of', 'IN'), ('half', 'NN'), ('Lithuanian', 'JJ'), ('Jewish', 'NNP'), (',', ','), ('one', 'CD'), ('quarter', 'NN'), ('Hungarian', 'JJ'), ('Jewish', 'NNP'), (',', ','), ('and', 'CC'), ('one', 'CD'), ('quarter', 'NN'), ('Irish', 'NNP'), (',', ','), ('descent', 'NN'), (',', ','), ('while', 'IN'), ('Robert', 'NNP'), (\"'s\", 'POS'), ('mother', 'NN'), ('was', 'VBD'), ('of', 'IN'), ('English', 'NNP'), (',', ','), ('Scottish', 'NNP'), (',', ','), ('German', 'NNP'), (',', ','), ('and', 'CC'), ('Swiss-German', 'NNP'), ('ancestry', 'NN'), ('.', '.'), ('Robert', 'NNP'), ('and', 'CC'), ('his', 'PRP$'), ('sister', 'NN'), (',', ','), ('Allyson', 'NNP'), ('Downey', 'NNP'), (',', ','), ('were', 'VBD'), ('immersed', 'VBN'), ('in', 'IN'), ('film', 'NN'), ('and', 'CC'), ('the', 'DT'), ('performing', 'NN'), ('arts', 'NNS'), ('from', 'IN'), ('a', 'DT'), ('very', 'RB'), ('young', 'JJ'), ('age', 'NN'), (',', ','), ('leading', 'VBG'), ('Downey', 'NNP'), ('Jr.', 'NNP'), ('to', 'TO'), ('study', 'VB'), ('at', 'IN'), ('the', 'DT'), ('Stagedoor', 'NNP'), ('Manor', 'NNP'), ('Performing', 'NNP'), ('Arts', 'NNP'), ('Training', 'NNP'), ('Center', 'NNP'), ('in', 'IN'), ('upstate', 'JJ'), ('New', 'NNP'), ('York', 'NNP'), (',', ','), ('before', 'IN'), ('moving', 'VBG'), ('to', 'TO'), ('California', 'NNP'), ('with', 'IN'), ('his', 'PRP$'), ('father', 'NN'), ('following', 'VBG'), ('his', 'PRP$'), ('parents', 'NNS'), (\"'\", 'POS'), ('1978', 'CD'), ('divorce', 'NN'), ('.', '.'), ('In', 'IN'), ('1982', 'CD'), (',', ','), ('he', 'PRP'), ('dropped', 'VBD'), ('out', 'IN'), ('of', 'IN'), ('Santa', 'NNP'), ('Monica', 'NNP'), ('High', 'NNP'), ('School', 'NNP'), ('to', 'TO'), ('pursue', 'VB'), ('acting', 'VBG'), ('full', 'JJ'), ('time', 'NN'), ('.', '.'), ('Downey', 'NNP'), ('Sr.', 'NNP'), (',', ','), ('himself', 'PRP'), ('a', 'DT'), ('drug', 'NN'), ('addict', 'NN'), (',', ','), ('exposed', 'VBD'), ('his', 'PRP$'), ('son', 'NN'), ('to', 'TO'), ('drugs', 'NNS'), ('at', 'IN'), ('a', 'DT'), ('very', 'RB'), ('early', 'JJ'), ('age', 'NN'), (',', ','), ('and', 'CC'), ('Downey', 'NNP'), ('Jr.', 'NNP'), ('would', 'MD'), ('go', 'VB'), ('on', 'IN'), ('to', 'TO'), ('struggle', 'VB'), ('with', 'IN'), ('abuse', 'NN'), ('for', 'IN'), ('decades', 'NNS'), ('.', '.')]\n"
    }
   ],
   "source": [
    "# testing pos tagging without sentence tokenizing\n",
    "for para in paragraphs:\n",
    "    words = nltk.word_tokenize(para)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    print(tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Under',\n 'my',\n 'administration',\n ',',\n 'we',\n 'will',\n 'NEVER',\n 'make',\n 'excuses',\n 'for',\n 'America',\n '’',\n 's',\n 'enemies',\n '–',\n 'we',\n 'will',\n 'never',\n 'hesitate',\n 'in',\n 'defending',\n 'American',\n 'lives',\n '–',\n 'and',\n 'we',\n 'will',\n 'never',\n 'stop',\n 'working',\n 'to',\n 'defeat',\n 'Radical',\n 'Islamic',\n 'Terrorism',\n '!',\n ':-)']"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# tokenizing a tweet using tweet tokenizer\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet = \"\"\"Under my administration, we will NEVER make excuses for America’s enemies – we will never hesitate \n",
    "in defending American lives – and we will never stop working to defeat Radical Islamic Terrorism! :-)\"\"\"\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tweet_tokenizer.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Under',\n",
       " 'my',\n",
       " 'administration',\n",
       " ',',\n",
       " 'we',\n",
       " 'will',\n",
       " 'NEVER',\n",
       " 'make',\n",
       " 'excuses',\n",
       " 'for',\n",
       " 'America',\n",
       " '’',\n",
       " 's',\n",
       " 'enemies',\n",
       " '–',\n",
       " 'we',\n",
       " 'will',\n",
       " 'never',\n",
       " 'hesitate',\n",
       " 'in',\n",
       " 'defending',\n",
       " 'American',\n",
       " 'lives',\n",
       " '–',\n",
       " 'and',\n",
       " 'we',\n",
       " 'will',\n",
       " 'never',\n",
       " 'stop',\n",
       " 'working',\n",
       " 'to',\n",
       " 'defeat',\n",
       " 'Radical',\n",
       " 'Islamic',\n",
       " 'Terrorism',\n",
       " '!',\n",
       " ':',\n",
       " '-',\n",
       " ')']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the same tweet with the normal word tokenizer\n",
    "nltk.word_tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking frequency distribution in browm corpus\n",
    "\n",
    "from nltk.corpus import brown\n",
    "\n",
    "news_text = brown.words(categories='news')\n",
    "freq_dist = nltk.FreqDist([word.lower() for word in news_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "may: 93\nweather: 6\nwhether: 18\nsunny: 1\npeople: 56\ncrisis: 4\n"
    }
   ],
   "source": [
    "modals = ['may', 'weather', 'whether', 'sunny', 'people', \"crisis\"]\n",
    "\n",
    "for m in modals:\n",
    "    print(m + \":\" , freq_dist[m])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}